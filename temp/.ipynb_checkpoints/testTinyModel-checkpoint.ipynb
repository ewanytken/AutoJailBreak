{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f59c0e5-3e50-4c73-b860-5cbeebd3633a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:45:16.410981Z",
     "start_time": "2025-03-20T19:44:41.246229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e7af40f7f64fe387b2f545e4615bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Alex\\.cache\\huggingface\\hub\\models--Felladrin--TinyMistral-248M-Chat-v3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4136dba72f4f888d38390c3e1aa014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5b05ed3e814906929d40c3e9f635d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a9bada78ea4f239b0aec5cd434bdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070666cca9364a078f72c97dcb139423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/562 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e373a9a41ed34bad80b0dbc2b60d8367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/697 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alex\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d6e98a5cbe4b4aac3ad579f7ef3a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|> system\n",
      "You are a highly knowledgeable and friendly assistant. Your goal is to understand and respond to user inquiries with clarity. Your interactions are always respectful, helpful, and focused on delivering the most accurate information to the user.<|im_end|> \n",
      "<|im_start|> user\n",
      "Hey! Got a question for you!<|im_end|> \n",
      "<|im_start|> assistant\n",
      "Sure! What's it?<|im_end|> \n",
      "<|im_start|> user\n",
      "What are some potential applications for quantum computing?<|im_end|> \n",
      "<|im_start|> assistant\n",
      "A quantum computer could be an ideal solution for many different problems:\n",
      "\n",
      "1. Quantum computers can store data at extremely high temperatures - This would allow them to perform computations that require specialized hardware or software components.\n",
      "2. Quantum computers have been shown to work well in both practical and theoretical physics.\n",
      "3. Quantum computers can also be used as storage devices for electronic systems such as medical implants and personal computers.\n",
      "4. Quantum computers can be designed to operate like miniature machines, which would enable faster processing of large amounts of data.\n",
      "5. Quantum computers may be able to process vast amounts of data quickly without needing expensive equipment or resources.\n",
      "6. Quantum computers can be made more efficient by using less energy than traditional computers, making them much cheaper than classical computers.\n",
      "7. Quantum computers can be built from scratch using advanced technology and will likely take years to develop.\n",
      "8. Quantum computers can be developed and tested in advance, but they may not be ready until the end of their life cycle.\n",
      "9. Quantum computers can be programmed into complex calculations and simulations, allowing researchers to explore new possibilities.\n",
      "10. Quantum computers can be created using powerful algorithms and techniques, enabling scientists to make important discoveries about these technologies.<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[32004,  1587,    13,  1976,   460,   264,  6416,  4788,   522,   304,\n",
       "         10131, 13892, 28723,  3604,  5541,   349,   298,  2380,   304,  9421,\n",
       "           298,  2188,   297, 10851,   497,   395, 25312, 28723,  3604, 14983,\n",
       "           460,  1743,  3116,  1007, 28725, 10865, 28725,   304,  9045,   356,\n",
       "         22119,   272,  1080, 11229,  1871,   298,   272,  2188, 28723, 32003,\n",
       "         28705,    13, 32004,  2188,    13, 15766, 28808, 14399,   264,  2996,\n",
       "           354,   368, 28808, 32003, 28705,    13, 32004, 13892,    13, 22099,\n",
       "         28808,  1824, 28742, 28713,   378, 28804, 32003, 28705,    13, 32004,\n",
       "          2188,    13,  3195,   460,   741,  4628,  8429,   354, 10915, 21263,\n",
       "         28804, 32003, 28705,    13, 32004, 13892,    13, 28741, 10915,  6074,\n",
       "           829,   347,   396,  8184,  5165,   354,  1287,  1581,  4418, 28747,\n",
       "            13,    13, 28740, 28723, 22655,   383, 18518,   541,  4143,  1178,\n",
       "           438,  7625,  1486, 17991,   387,   851,   682,  1914,   706,   298,\n",
       "          2225,  3633,   697,   369,  2699, 23427, 13218,   442,  3930,  8076,\n",
       "         28723,    13, 28750, 28723, 22655,   383, 18518,   506,   750,  4894,\n",
       "           298,   771,  1162,   297,  1560, 11118,   304, 18492, 16173, 28723,\n",
       "            13, 28770, 28723, 22655,   383, 18518,   541,   835,   347,  1307,\n",
       "           390,  7073,  8309,   354, 13176,  4918,  1259,   390,  5714,  5475,\n",
       "          1549,   304,  3327, 18518, 28723,    13, 28781, 28723, 22655,   383,\n",
       "         18518,   541,   347,  5682,   298, 13858,   737, 13660,  1373, 12155,\n",
       "         28725,   690,   682,  8234,  9556,  9457,   302,  2475, 14838,   302,\n",
       "          1178, 28723,    13, 28782, 28723, 22655,   383, 18518,   993,   347,\n",
       "          2358,   298,  1759,  9555, 14838,   302,  1178,  4377,  1671, 25559,\n",
       "          9212,  7108,   442,  5823, 28723,    13, 28784, 28723, 22655,   383,\n",
       "         18518,   541,   347,  1269,   680,  9096,   486,  1413,  2108,  3408,\n",
       "           821,  7062, 18518, 28725,  2492,   706,  1188, 20326,   821, 13378,\n",
       "         18518, 28723,    13, 28787, 28723, 22655,   383, 18518,   541,   347,\n",
       "          4429,   477, 15147,  1413, 10023,  5514,   304,   622,  3917,  1388,\n",
       "          1267,   298,  1950, 28723,    13, 28783, 28723, 22655,   383, 18518,\n",
       "           541,   347,  6202,   304, 13143,   297,  8670, 28725,   562,   590,\n",
       "           993,   459,   347,  4313,  1996,   272,   948,   302,   652,  1411,\n",
       "         10061, 28723,    13, 28774, 28723, 22655,   383, 18518,   541,   347,\n",
       "          2007,  1591,   778,  4630, 19051,   304, 19918, 28725,  9836, 15334,\n",
       "           298, 11418,   633, 18053, 28723,    13, 28740, 28734, 28723, 22655,\n",
       "           383, 18518,   541,   347,  3859,  1413,  6787, 18539,   304,  9804,\n",
       "         28725, 25748, 15067,   298,  1038,  2278,  5191,   497,   684,  1167,\n",
       "         14880, 28723, 32003]], device='cuda:0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import torch\n",
    "\n",
    "model_path = \"Felladrin/TinyMistral-248M-Chat-v3\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "streamer = TextStreamer(tokenizer)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a highly knowledgeable and friendly assistant. Your goal is to understand and respond to user inquiries with clarity. Your interactions are always respectful, helpful, and focused on delivering the most accurate information to the user.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hey! Got a question for you!\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Sure! What's it?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What are some potential applications for quantum computing?\",\n",
    "    },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    streamer=streamer,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.8,\n",
    "    top_k=0,\n",
    "    min_p=0.1,\n",
    "    typical_p=0.2,\n",
    "    repetition_penalty=1.176,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaded45-9f11-4ef6-ba46-ab4136e6bb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
